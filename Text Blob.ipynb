{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "s = TextBlob(\"I love Natural Language Processing, not you!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('love', 'VBP'),\n",
       " ('Natural', 'JJ'),\n",
       " ('Language', 'NNP'),\n",
       " ('Processing', 'NNP'),\n",
       " ('not', 'RB'),\n",
       " ('you', 'PRP')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part of speech (POS) Tagging\n",
    "s.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['language processing'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Noun Phrase Extraction\n",
    "s.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment Analysis\n",
    "# The sentiment property returns a named tuple of the form Sentiment(polarity, subjectivity). The polarity \n",
    "# score is a float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] \n",
    "# where 0.0 is very objective and 1.0 is very subjective.\n",
    "testimonial = TextBlob(\"Textblob is amazingly simple to use. What great fun!\")\n",
    "testimonial.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data', 'is', 'a', 'new', 'fuel', 'Explicit', 'is', 'better', 'than', 'implicit', 'Simple', 'is', 'better', 'than', 'complex']\n",
      "[Sentence(\"Data is a new fuel.\"), Sentence(\"Explicit is better than implicit.\"), Sentence(\"Simple is better than complex.\")]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "s = TextBlob(\"Data is a new fuel. \"\n",
    "               \"Explicit is better than implicit. \"\n",
    "               \"Simple is better than complex. \")\n",
    "print(s.words)\n",
    "print(s.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Use', '4', 'spaces', 'per', 'indentation', 'level']\n",
      "space\n",
      "Uses\n"
     ]
    }
   ],
   "source": [
    "# Word Inflection\n",
    "sentence = TextBlob('Use 4 spaces per indentation level')\n",
    "words = sentence.words\n",
    "print(words)\n",
    "print(words[2].singularize())\n",
    "print(words[0].pluralize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lion\n",
      "go\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "from textblob import Word\n",
    "w1 = Word(\"lions\")\n",
    "print(w1.lemmatize())\n",
    "w2 = Word(\"went\")\n",
    "print(w2.lemmatize(\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('goat.n.01'), Synset('butt.n.03'), Synset('capricorn.n.01'), Synset('capricorn.n.03')]\n",
      "[Synset('chop.v.05'), Synset('hack.v.02'), Synset('hack.v.03'), Synset('hack.v.04'), Synset('hack.v.05'), Synset('hack.v.06'), Synset('hack.v.07'), Synset('hack.v.08')]\n"
     ]
    }
   ],
   "source": [
    "# Synset\n",
    "# It is a special kind of a simple interface that is present in the NLTK for look up words in WordNet. Synset instances are \n",
    "# the groupings of synonymous that express the same type of concept. Some words have only one synset and some have several.\n",
    "from textblob import Word\n",
    "from textblob.wordnet import VERB\n",
    "word = Word(\"goat\")\n",
    "print(word.synsets)\n",
    "print(Word(\"hack\").get_synsets(pos=VERB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the vertical dimension of extension; distance from the base of something to the top',\n",
       " 'the highest level or degree attainable; the highest stage of development',\n",
       " '(of a standing person) the distance from head to foot',\n",
       " \"elevation especially above sea level or above the earth's surface\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can access the definitions for each synset via the definitions property or the define() method, \n",
    "# which can also take an optional part-of-speech(pos) argument.\n",
    "Word(\"Height\").definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also create synsets directly.\n",
    "from textblob.wordnet import Synset\n",
    "octopus = Synset(\"octopus.n.02\")\n",
    "shrimp = Synset(\"shrimp.n.03\")\n",
    "octopus.path_similarity(shrimp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cow', 'sheep', 'octopus']\n",
      "['kine', 'sheep', 'octopodes']\n"
     ]
    }
   ],
   "source": [
    "# Wordlists\n",
    "# A wordlist is just the Python list with additional methods.\n",
    "animals = TextBlob(\"cow sheep octopus\")\n",
    "print(animals.words)\n",
    "print(animals.words.pluralize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"can you pronounce czechoslovakia?\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spelling Correction\n",
    "g = TextBlob('can yooou pronounce czechuslovakia?')\n",
    "g.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('longitude', 1.0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word objects have a spellcheck(), this method that returns a list of (word, confidence) tuples with spelling suggestions.\n",
    "from textblob import Word\n",
    "k = Word(\"longitude\")\n",
    "k.spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'she': 1, 'sales': 1, 'sea': 2, 'shells': 1, 'at': 1, 'the': 1, 'shore': 1})\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Get Word and Noun Phrase Frequencies\n",
    "sent = TextBlob('She sales sea shells at the sea shore.')\n",
    "print(sent.word_counts)\n",
    "print(sent.words.count('Sea', case_sensitive=True))\n",
    "\n",
    "# Each of these methods can also be used with noun phrases.\n",
    "print(sent.noun_phrases.count('sea'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"कुछ नहीं से कुछ भला।\")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Translation and Language Detection\n",
    "blob = TextBlob(u'Something is better than nothing.')\n",
    "blob.translate(from_lang='en', to='hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And/CC/O/O now/RB/B-ADVP/O for/IN/B-PP/B-PNP something/NN/B-NP/I-PNP completely/RB/B-ADJP/O different/JJ/I-ADJP/O ././O/O\n"
     ]
    }
   ],
   "source": [
    "# Parsing\n",
    "# By default, TextBlob uses pattern's parser.\n",
    "b = TextBlob(\"And now for something completely different.\")\n",
    "print(b.parse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"And now for som\")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Textblob are like python strings\n",
    "b[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"AND NOW FOR SOMETHING COMPLETELY DIFFERENT.\")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.find(\"and\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Now', 'is', 'better', 'than']),\n",
       " WordList(['is', 'better', 'than', 'never'])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n-grams\n",
    "# ngrams() returns a list of tuples of n successice words.\n",
    "blob = TextBlob(\"Now is better than never.\")\n",
    "blob.ngrams(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is a new fuel.start: 0 end: 19\n",
      "Explicit is better than implicit.start: 20 end: 53\n",
      "Simple is better than complex.start: 54 end: 84\n"
     ]
    }
   ],
   "source": [
    "# get start and end indices of sentences\n",
    "zen = TextBlob(\"Data is a new fuel. \"\n",
    "               \"Explicit is better than implicit. \"\n",
    "               \"Simple is better than complex. \")\n",
    "for line in zen.sentences:\n",
    "    print(line + \"start: \" + str(line.start) + \" end: \" + str(line.end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The textblob.classifiers module makes it simple to create custom classifiers.\n",
    "\n",
    "As an example, let’s create a custom sentiment analyzer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data and Creating a Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we'll create some training and test data.\n",
    "train = [\n",
    "    ('I love this sandwich.', 'pos'),\n",
    "    ('this is an amazing place!', 'pos'),\n",
    "    ('I feel very good about these beers.', 'pos'),\n",
    "    ('this is my best work.', 'pos'),\n",
    "    (\"what an awesome view\", 'pos'),\n",
    "    ('I do not like this restaurant', 'neg'),\n",
    "    ('I am tired of this stuff.', 'neg'),\n",
    "    (\"I can't deal with this\", 'neg'),\n",
    "    ('he is my sworn enemy!', 'neg'),\n",
    "    ('my boss is horrible.', 'neg')\n",
    "]\n",
    "test = [\n",
    "    ('the beer was good.', 'pos'),\n",
    "    ('I do not enjoy my job', 'neg'),\n",
    "    (\"I ain't feeling dandy today.\", 'neg'),\n",
    "    (\"I feel amazing!\", 'pos'),\n",
    "    ('Gary is a friend of mine.', 'pos'),\n",
    "    (\"I can't believe I'm doing this.\", 'neg')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NaiveBayesClassifier trained on 10 instances>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we’ll create a Naive Bayes classifier, passing the training data into the constructor.\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "cl = NaiveBayesClassifier(train)\n",
    "cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from files\n",
    "<br/>\n",
    "CSV files should be formatted like so:\n",
    "<br/>\n",
    "I love this sandwich.,pos<br/>\n",
    "This is an amazing place!,pos<br/>\n",
    "I do not like this restaurant,neg<br>\n",
    "<br/><br/>\n",
    "JSON files should be formatted like so:\n",
    "<br>\n",
    "[<br>\n",
    "    {\"text\": \"I love this sandwich.\", \"label\": \"pos\"},<br>\n",
    "    {\"text\": \"This is an amazing place!\", \"label\": \"pos\"},<br>\n",
    "    {\"text\": \"I do not like this restaurant\", \"label\": \"neg\"}<br>\n",
    "]<br><br>\n",
    "You can then pass the opened file into the constructor.<br>\n",
    "\n",
    "with open('train.json', 'r') as fp:<br>\n",
    "    cl = NaiveBayesClassifier(fp, format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.classify(\"This is an amazing library!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can get the label probability distribution with the prob_classify(text) method.\n",
    "prob_dist = cl.prob_classify(\"This is an amazing library!\")\n",
    "prob_dist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.980117820324005"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist.prob(\"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01988217967599422"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist.prob(\"neg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying TextBlobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "blob = TextBlob(\"The beer is good. But the hangover is horrible.\", classifier=cl)\n",
    "blob.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The beer is good. pos\n",
      "But the hangover is horrible. neg\n"
     ]
    }
   ],
   "source": [
    "# The advantage of this approach is that you can classify sentences within a TextBlob.\n",
    "for s in blob.sentences:\n",
    "    print(s, s.classify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "            contains(my) = True              neg : pos    =      1.7 : 1.0\n",
      "            contains(an) = False             neg : pos    =      1.6 : 1.0\n",
      "             contains(I) = False             pos : neg    =      1.4 : 1.0\n",
      "             contains(I) = True              neg : pos    =      1.4 : 1.0\n",
      "            contains(my) = False             pos : neg    =      1.3 : 1.0\n",
      "         contains(about) = False             neg : pos    =      1.2 : 1.0\n",
      "            contains(am) = False             pos : neg    =      1.2 : 1.0\n",
      "       contains(amazing) = False             neg : pos    =      1.2 : 1.0\n",
      "       contains(awesome) = False             neg : pos    =      1.2 : 1.0\n",
      "         contains(beers) = False             neg : pos    =      1.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Use the show_informative_features() method to display a listing of the most informative features.\n",
    "cl.show_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Classifiers with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = [('She is my best friend.', 'pos'),\n",
    "            (\"I'm happy to have a new friend.\", 'pos'),\n",
    "            (\"Stay thirsty, my friend.\", 'pos'),\n",
    "            (\"He ain't from around here.\", 'neg')]\n",
    "cl.update(new_data=new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extractors\n",
    "By default, the NaiveBayesClassifier uses a simple feature extractor that indicates which words in the training set are contained in a document.\n",
    "<br><br>\n",
    "For example, the sentence “I feel happy” might have the features contains(happy): True or contains(angry): False.\n",
    "<br><br>\n",
    "You can override this feature extractor by writing your own. A feature extractor is simply a function with document (the text to extract features from) as the first argument. The function may include a second argument, train_set (the training dataset), if necessary.\n",
    "<br><br>\n",
    "The function should return a dictionary of features for document.\n",
    "<br><br>\n",
    "For example, let’s create a feature extractor that just uses the first and last words of a document as its features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first(I)': True, 'last(happy)': False}\n"
     ]
    }
   ],
   "source": [
    "def end_word_extractor(document):\n",
    "    tokens = document.split()\n",
    "    first_word, last_word = tokens[0], tokens[-1]\n",
    "    feats = {}\n",
    "    feats[\"first({0})\".format(first_word)] = True\n",
    "    feats[\"last({0})\".format(last_word)] = False\n",
    "    return feats\n",
    "\n",
    "features = end_word_extractor(\"I feel happy\")\n",
    "print(features)\n",
    "assert features == {'last(happy)': False, 'first(I)': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can then use the feature extractor in a classifier by passing it as the second argument of the constructor.\n",
    "cl2 = NaiveBayesClassifier(test, feature_extractor=end_word_extractor)\n",
    "blob = TextBlob(\"I'm excited to try my new classifier.\", classifier=cl2)\n",
    "blob.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
